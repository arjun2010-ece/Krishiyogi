// AWS IMAGE UPLOAD.........

const Category = require("../models/category");
const slugify = require("slugify");
const formidable = require("formidable");
const AWS = require("aws-sdk");
const {uuid} = require("uuidv4");
const fs = require("fs");


//s3
const s3 = new AWS.S3({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
    region: process.env.AWS_REGION
});


exports.create = (req, res) => {
    let form = new formidable.IncomingForm();
    form.parse(req, (err, fields, files) => {
        if(err){
            return res.status(400).json({ error: "Image could not upload"});
        }

        const {name, content} = fields;
        const {image} = files;

        const slug = slugify(name);

        let category = new Category({name, content, slug});
        if(image.size > 2000000){
            return res.status(400).json({ error: "Image should be less than 2mb."});
        }
        //upload image to s3
        const params = {
            Bucket: "react-node-awss",
            Key: `category/${uuid()}`,
            Body: fs.readFileSync(image.path),
            ACL: "public-read",
            ContentType:  `image/jpg`  //IT IS OPTIONAL, LIMITING ONLY YO JPG
        }

        s3.upload(params, (err, data)=>{
            if(err){
                console.log(err);
                return res.status(400).json({ error: "Upload to s3 failed"});
            }
            console.log("AWS UPLOAD RES DATA", data);
            category.image.url = data.Location;
            category.image.key = data.Key;

            // save to db
            category.save((err, success) => {
                if(err){
                    return res.status(400).json({ error: "Error saving category to database"});
                }
                return res.json(success);
            });
        })

    });
}

============================================================================

BASE 64 IMAGE DATA UPLOAD to S3::
-------------------------------
Not all the time we upload the image as it is, many time to speed up page performance we upload base 64 image.
base 64 converts images into a sequence of letters and numbers and thus make it a part of html so we dont need to make a separate request to
images, it will come as part of html and css, so one requests less and speed up page.


```
//uploading base 64 image data
exports.create = (req, res) => {
    const {name, content, image} = req.body;

    //base64 image data
    const base64data = new Buffer.from(image.replace(/^data:image\/\w+;base64,/, ""), "base64");
    const type = image.split(";")[0].split("/")[1];

    //   upload image to s3
        const params = {
            Bucket: "react-node-awss",
            Key: `category/${uuid()}.${type}`,
            Body: base64data,
            ACL: "public-read",
            ContentEncoding: "base64",
            ContentType:  `image/${type}`
        }

        const slug = slugify(name);
        let category = new Category({name, content, slug});

            s3.upload(params, (err, data) => {
            if(err){
                console.log(err);
                return res.status(400).json({ error: "Upload to s3 failed"});
            }
            console.log("AWS UPLOAD RES DATA", data);
            category.image.url = data.Location;
            category.image.key = data.Key;

            // save to db
            category.save((err, success) => {
                if(err){
                    return res.status(400).json({ error: "Error saving category to database"});
                }
                return res.json(success);
            });
        })

}


```











